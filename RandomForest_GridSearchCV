##### RANDOM FOREST + GRIDSEARCHCV #####

rf = RandomForestClassifier(max_features='auto', oob_score=True, random_state=0, n_jobs=-1)

param_grid = { "criterion" : ["gini", "entropy"],
              "min_samples_leaf" : [5, 10],
              "min_samples_split" : [5, 10],
              "n_estimators": [30, 60, 90]}

clf = GridSearchCV(estimator=rf,
                   param_grid=param_grid,
                   scoring='balanced_accuracy',
                   cv=2, n_jobs=-1)
clf = clf.fit(df.values, target)

print(clf.best_score_)
print(clf.best_params_)
y_pred = clf.predict(df.values)
y_pred_proba = clf.predict_proba(df.values)


#best_estimator_ : estimator or dict
#Estimator that was chosen by the search, i.e. estimator which gave highest score 
#(or smallest loss if specified) on the left out data. Not available if refit=False.

#See refit parameter for more information on allowed values.

#best_score_ : float
#Mean cross-validated score of the best_estimator

#For multi-metric evaluation, this is present only if refit is specified.

#best_params_ : dict
#Parameter setting that gave the best results on the hold out data.

#For multi-metric evaluation, this is present only if refit is specified.

#best_index_ : int
#The index (of the cv_results_ arrays) which corresponds to the best candidate parameter setting.

#The dict at search.cv_results_['params'][search.best_index_] gives the parameter setting for 
#the best model, that gives the highest mean score (search.best_score_).

#For multi-metric evaluation, this is present only if refit is specified.

##### RANDOM FOREST + GRIDSEARCHCV #####
